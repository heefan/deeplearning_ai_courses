{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogen in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.2.35)\n",
      "Requirement already satisfied: diskcache in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyautogen) (5.6.3)\n",
      "Requirement already satisfied: docker in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyautogen) (7.1.0)\n",
      "Requirement already satisfied: flaml in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyautogen) (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.17.0 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyautogen) (1.26.3)\n",
      "Requirement already satisfied: openai>=1.3 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyautogen) (1.6.1)\n",
      "Requirement already satisfied: packaging in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyautogen) (23.2)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyautogen) (2.5.3)\n",
      "Requirement already satisfied: python-dotenv in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyautogen) (1.0.0)\n",
      "Requirement already satisfied: termcolor in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyautogen) (2.4.0)\n",
      "Requirement already satisfied: tiktoken in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyautogen) (0.5.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai>=1.3->pyautogen) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai>=1.3->pyautogen) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai>=1.3->pyautogen) (0.26.0)\n",
      "Requirement already satisfied: sniffio in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai>=1.3->pyautogen) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai>=1.3->pyautogen) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai>=1.3->pyautogen) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.14.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/litian/Library/Python/3.11/lib/python/site-packages (from docker->pyautogen) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/litian/Library/Python/3.11/lib/python/site-packages (from docker->pyautogen) (2.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken->pyautogen) (2023.12.25)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/litian/Library/Python/3.11/lib/python/site-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/litian/Library/Python/3.11/lib/python/site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/litian/.pyenv/versions/3.11.6/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/litian/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->docker->pyautogen) (3.3.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! What do you call a fish wearing a crown? King Neptune! *ba-dum-tss* Your turn, Joe!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, that's a good one, Cathy! Here's one for you: Why did the scarecrow win an award? Because he was outstanding in his field! *ba-dum-tss*\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, I love it, Joe! Here's another one for you: Why did the math book look sad? Because it had too many problems! *ba-dum-tss*\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "I gotta go\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ChatResult(chat_id=None,\n",
      "           chat_history=[{'content': \"I'm Joe. Cathy, let's keep the jokes \"\n",
      "                                     'rolling.',\n",
      "                          'name': 'joe',\n",
      "                          'role': 'assistant'},\n",
      "                         {'content': 'Hey Joe! What do you call a fish wearing '\n",
      "                                     'a crown? King Neptune! *ba-dum-tss* Your '\n",
      "                                     'turn, Joe!',\n",
      "                          'name': 'cathy',\n",
      "                          'role': 'user'},\n",
      "                         {'content': \"Haha, that's a good one, Cathy! Here's \"\n",
      "                                     'one for you: Why did the scarecrow win '\n",
      "                                     'an award? Because he was outstanding in '\n",
      "                                     'his field! *ba-dum-tss*',\n",
      "                          'name': 'joe',\n",
      "                          'role': 'assistant'},\n",
      "                         {'content': \"Haha, I love it, Joe! Here's another one \"\n",
      "                                     'for you: Why did the math book look sad? '\n",
      "                                     'Because it had too many problems! '\n",
      "                                     '*ba-dum-tss*',\n",
      "                          'name': 'cathy',\n",
      "                          'role': 'user'},\n",
      "                         {'content': 'I gotta go',\n",
      "                          'name': 'cathy',\n",
      "                          'role': 'user'}],\n",
      "           summary='Joe and Cathy are exchanging jokes and having a good time '\n",
      "                   'with puns.',\n",
      "           cost={'usage_excluding_cached_inference': {'total_cost': 0},\n",
      "                 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 122,\n",
      "                                                                             'cost': 0.00040500000000000003,\n",
      "                                                                             'prompt_tokens': 444,\n",
      "                                                                             'total_tokens': 566},\n",
      "                                                      'total_cost': 0.00040500000000000003}},\n",
      "           human_input=[])\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent\n",
    "from pprint import pprint\n",
    "\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}\n",
    "\n",
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\"your name is Cathy and you are a stand-up comedian. when you're ready to end the conversation, please say 'I gotta go'\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg['content']\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\"your name is Joe and you are a stand-up comedian. when you're ready to end the conversation, please say 'I gotta go'\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg['content']\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")\n",
    "cathy.send(message=\"I gotta go\", recipient=joe)\n",
    "pprint(chat_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
