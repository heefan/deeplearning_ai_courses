"""
Critic Agent for reviewing and providing feedback on generated code.

This agent uses ADK to review Python code generated by the Generator Agent,
checking for correctness, best practices, and requirements adherence.
"""

from typing import Dict, Any, List, Optional
import asyncio
from dataclasses import dataclass
from enum import Enum

from google.adk import Agent, AgentConfig
from google.adk.models import ModelConfig

from ..utils.prompt_templates import CRITIC_PROMPT_TEMPLATE


class CritiqueResult(Enum):
    """Possible results from the critic agent."""
    APPROVED = "approved"
    NEEDS_IMPROVEMENT = "needs_improvement"
    REJECTED = "rejected"


@dataclass
class CritiqueResponse:
    """Response from the critic agent."""
    result: CritiqueResult
    feedback: str
    suggestions: List[str]
    confidence: float
    issues: List[str]


class CriticAgent:
    """
    ADK agent that reviews generated Python code for quality and correctness.
    
    This agent analyzes code generated by the Generator Agent and provides
    structured feedback on improvements needed.
    """
    
    def __init__(
        self,
        model_config: ModelConfig,
        max_retries: int = 3
    ):
        """
        Initialize the critic agent.
        
        Args:
            model_config: ADK model configuration for LMStudio
            max_retries: Maximum number of retry attempts
        """
        self.model_config = model_config
        self.max_retries = max_retries
        self._agent: Optional[Agent] = None
    
    async def _initialize_agent(self) -> None:
        """Initialize the ADK agent if not already done."""
        if self._agent is None:
            agent_config = AgentConfig(
                model_config=self.model_config,
                system_prompt=self._build_system_prompt(),
                structured_output=True
            )
            self._agent = Agent(agent_config)
    
    def _build_system_prompt(self) -> str:
        """Build the system prompt for the critic agent."""
        return CRITIC_PROMPT_TEMPLATE
    
    async def critique_code(
        self,
        code: str,
        user_query: str,
        context: Optional[Dict[str, Any]] = None
    ) -> CritiqueResponse:
        """
        Review and critique generated Python code.
        
        Args:
            code: The Python code to review
            user_query: Original user query for context
            context: Optional context for the critique
            
        Returns:
            CritiqueResponse containing the critique results
            
        Raises:
            RuntimeError: If agent fails to critique code after retries
        """
        await self._initialize_agent()
        
        if context is None:
            context = {}
        
        prompt = self._build_critique_prompt(code, user_query, context)
        
        for attempt in range(self.max_retries):
            try:
                response = await self._agent.generate(
                    prompt=prompt,
                    structured_output=True
                )
                
                # Parse the structured response
                return self._parse_response(response)
                
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise RuntimeError(
                        f"Critic agent failed after {self.max_retries} attempts: {e}"
                    )
                await asyncio.sleep(1)  # Brief delay before retry
        
        raise RuntimeError("Critic agent failed unexpectedly")
    
    def _build_critique_prompt(
        self,
        code: str,
        user_query: str,
        context: Dict[str, Any]
    ) -> str:
        """Build the prompt for code critique."""
        prompt = f"User Query: {user_query}\n\n"
        prompt += f"Generated Code:\n```python\n{code}\n```\n\n"
        
        if context.get("previous_critiques"):
            prompt += "Previous critiques:\n"
            for i, critique in enumerate(context["previous_critiques"], 1):
                prompt += f"Critique {i}: {critique.get('feedback', 'N/A')}\n"
        
        prompt += "Please review this code and provide your critique."
        return prompt
    
    def _parse_response(self, response: Dict[str, Any]) -> CritiqueResponse:
        """Parse the structured response from the critic agent."""
        try:
            result_str = response.get("result", "needs_improvement").lower()
            result = CritiqueResult(result_str) if result_str in [e.value for e in CritiqueResult] else CritiqueResult.NEEDS_IMPROVEMENT
            
            feedback = response.get("feedback", "")
            suggestions = response.get("suggestions", [])
            confidence = float(response.get("confidence", 0.0))
            issues = response.get("issues", [])
            
            # Ensure suggestions is a list
            if not isinstance(suggestions, list):
                suggestions = [str(suggestions)] if suggestions else []
            
            # Ensure issues is a list
            if not isinstance(issues, list):
                issues = [str(issues)] if issues else []
            
            return CritiqueResponse(
                result=result,
                feedback=feedback,
                suggestions=suggestions,
                confidence=confidence,
                issues=issues
            )
            
        except (KeyError, ValueError, TypeError) as e:
            raise RuntimeError(f"Failed to parse critic response: {e}")
    
    async def close(self) -> None:
        """Close the agent and clean up resources."""
        if self._agent:
            await self._agent.close()
            self._agent = None
